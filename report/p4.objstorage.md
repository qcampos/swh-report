# Object Storage

####

Lorsque les fichiers source sont capturés par un loader (voir
\ref{loaders-collect} p.\pageref{loaders-collect}), ils sont enregistrés dans
l'**object storage** dont le but est de conserver les fichiers et d'en
restituer leur contenu à la demande.

## Principe et fonctionnement

####

L'object storage de Software Heritage est un *blob-storage*
clef-valeur dans lequel chaque *blob* est référencé par son sha1 (voir
\ref{data-model} p.\pageref{data-model}).

####

Initialement, l'object storage était une classe entièrement dépendante
du storage, et n'existait pas sans elle (voir figure
\ref{storage-initial} p.\pageref{storage-initial}). Au cours du
développement, l'object storage a pris de plus en plus d'importance et
d'indépendance jusqu'à être déplacé dans son propre package python
(depuis `swh.storage.objstorage` vers `swh.objstorage`.

![Architecture initiale du Storage \label{storage-initial}](storage_initial.pdf)



## Les modifications

####

L'object storage est le composant le plus au coeur de Software
Heritage, car c'est lui qui est en charge de stocker les fichiers
sources bruts, dont les méta-données sont dans la base de donnée. Pour
cette raison, c'est un composant qui est appelé à évoluer souvent
pour devenir de plus en plus riche lorsque de nouvelles
fonctionnalités sont nécessaires.

####

Cette section retrace les modifications effectuées sur l'object
storage au cours de mon stage, ainsi que les raisons qui ont motivé ces
changements.

### RemoteObjStorage API

####

Créer l'archiver (voir \ref{archiver} p.\pageref{archiver}) nécessite
d'avoir sur la machine de sauvegarde un moyen de recevoir les objets
copiés et de les stocker de la même manière que sur la machine
source : un serveur http qui puisse recevoir les requêtes nécessaires
et les déléguer à un *blob-storage*.

####

Comme les données sauvegardées n'ont pas besoin d'être manipulées mais
uniquement présentes, déployer un serveur `Storage` (qui possède déjà
une version remote http) implique une surcouche contingente.

####

Afin de remplir les objectifs de l'archiver tout en étant efficace, il
a fallu ajouter un serveur http pour l'object storage. Le schéma
\ref{objstorage-api} p.\pageref{objstorage-api} montre le
fonctionnement de cette nouvelle API.

![API http pour ObjStorage \label{objstorage-api}](objstorage_api.pdf)


### Interface ObjStorage

####

L'introduction de ce `RemoteObjStorage` (voir section précédente
\ref{remoteobjstorage-api} p.\pageref{remoteobjstorage-api}) qui
possède les mêmes fonctionnalités et une API similaire à
l'`ObjStorage`, induit la nécessité d'une interface commune afin que
les modifications d'API n'empêchent pas le duck typing de fonctionner
correctement et les deux types d'object storage d'être interchangés de
manière invisible.

####

On introduit donc une interface dont vont hériter les deux classes
d'object storage, et le code initial de `ObjStorage` est déplacé dans
la classe `PathSlicingObjStorage` (voir schéma
\ref{interface-initiale} p.\pageref{interface-initiale}).

![Ajout de l'interface ObjStorage \label{interface-initiale}](interface_initiale.pdf)

####

En python, le duck-typing rend inutile la présence d'interfaces
puisque l'existence des méthodes est vérifiée en runtime. En réalité,
les interfaces sont des classes abstraites dont toutes les méthodes
lèvent l'exception `NotImplementedError`. Si une implémentation de la
super classe ne respecte pas son contrat, l'erreur est levée et
explique l'absence d'implantation de la méthode.

####

```python
	class ObjStorage():
		...
		def get(self, obj_id):
			""" Retrieve the content referenced by the given id. """
			raise NotImplementedError('Class %s must implement "get" method' % type(self))
		...
```

####

Toutefois, cette solution seule n'est pas suffisante. L'erreur est
détectée au cours de l'exécution et n'apporte pas la même sécurité
qu'une interface dans un langage compilé.

####

Python, depuis la version 2.6 contient un module `abc` qui fournit des
fonctionnalités utilisées pour faire des classes de base abstraites
(Abstract Base Class). Ces classes permettent de forcer
l'implantation des méthodes dans les classes filles, sans quoi une
exception est levée à la création de l'objet de la classe fille. Cela
permet de capturer cette erreur plus tôt et de ne pas la manquer, si
la couverture des tests ne permettait pas de détecter l'erreur.

####

```python
	import abc

	class ObjStorage(metaclass=abc.ABCMeta):
		...
		@abc.abstractmethod
		def get(self, obj_id):
			""" Retrieve the content referenced by the given id. """
			raise NotImplementedError('Class %s must implement "get" method' % type(self))
		...
```

####

La méthode conserve toutefois son exception `NotImplementedError` dans
le cas ou la classe fille redéfinit la méthode mais fait appel à la
méthode de la classe parent.

```python
	class PathSlicingObjStorage(ObjStorage):
		def get(self, obj_id):
			super().get(obj_id)

```


### PathSlicingObjStorage paramétré

####

La classe `PathSlicingObjStorage` est l'implantation de `ObjStorage`
qui effectue concrètement le stockage des fichiers sur le disque (voir
\ref{data-model} p.\pageref{data-model}).

####

Lors de l'ajout d'un fichier à l'object storage, le sha1 de son
contenu est calculé et lui sert d'identifiant. Cet identifiant définit
l'arborescence dans laquelle le fichier va être stocké sur le disque.

Par exemple, un fichier `foo.txt` dont le sha1 est `abcdef1234` est
stocké sur le disque sous `<storage root>/ab/cd/ef/abcdef1234`.

####

La création d'une telle arborescence permet de limiter le nombre de
fichiers dans un même répertoire, nombre qui à notre échelle est mal
supporté par le système de fichier XFS.

####

Cependant, pour accéder à un fichier, il est nécessaire d'ouvrir trois
répertoires, c'est à dire accéder à trois inodes et passer par autant
d'indirections. En passant à un système de fichier comme Ext4 pour qui
le nombre de fichiers dans un répertoire n'est pas un facteur de
ralentissement, il est possible de créer un stockage sur disque avec
moins de découpe et donc moins de profondeur.

####

Seulement, la place disponible sur le stockage ne permet pas de faire
une migration *en place* de tous les fichiers en une seule fois. Il
est donc nécessaire de faire le déplacement partition par partition,
au nombre de 16. Cette transition lente nécessite d'avoir
simultanément plusieurs object storage dont la manière de découper
l'identifiant diffère.

####

La classe `PathSlicingObjStorage` à donc été modifiée de manière à ce
que la manière dont le sha1 est découpé soit passé comme un argument.

####

Au lieu de faire des découpes régulières, le `PathSlicingObjStorage`
prend un argument une chaîne de caractère dont le contenu définit la
taille des découpes. Cette syntaxe est basée sur le *slice* des
iterables de python.

Par exemple, la chaîne `"0:2/2:4/4:6"` correspond à la découpe
initiale de l'identifiant, où le premier répertoire est nommé en
fonction des deux premiers caractères (de 0 jusqu'à 2 exclu), puis des
deux suivants (de 2 jusqu'à 4 exclu), et ainsi de suite.

####

La découpe choisie pour le nouveau stockage sur Ext4 est `"0:1/0:5/"`,
où le premier caractère ne représente que les points de montages
virtuels des seize partitions.

####

Cet argument est donc parsé par le `PathSlicingObjStorage` et produit
des informations pour la découpe de l'identifiant.

####

```python
	class PathSlicingObjStorage(ObjStorage):
		def __init__(self, root, slicing):
			# La chaine est parsee de telle sorte a produire
			# une liste de couple (debut, fin) pour chaque
			# partie.
			self.root = root
			self.bounds = [
				slice(*map(int, sbounds.split(':')))
				for sbounds in slicing.split('/')
				if sbounds
			]
```

####

```python
		def _obj_dir(self, hex_obj_id):
			""" Compute the path of an object
			Args:
				hex_obj_id (str): hex representation of the object id
			Returns:
				path to the directory where the content should be.
			"""
			# Ces couples sont utilises pour former des morceaux
			# d'identifiant qui sont assembles pour former un path
			slices = [hex_obj_id[bound] for bound in self.bounds]
			return os.path.join(self.root, *slices)
```

####

Ainsi, il est possible d'avoir plusieurs object storage qui ont une
manière de stocker les fichiers différentes, et d'effectuer une
transition partition par partition afin de ne pas dupliquer la
totalité du contenu avant d'effacer l'ancienne version.

####

Lorsqu'une partition est migrée, et les deux object storage mis en
place, si un contenu est ajouté qui correspond à une partition migrée,
il doit être ajouté au nouvel object storage, mais pas à l'ancien. De
même, lorsqu'un contenu est demandé, il doit être récupéré peu importe
sur quel stockage il est.

### ObjStorage demultiplexer

####

Le rôle d'un demultiplexer est de recevoir des requêtes, et de les
répartir à ses composants. En demultiplexant les fonctions de
`ObjStorage` vers les deux instances de `PathSlicingObjStorage`, il
devient possible d'avoir de manière invisible les deux object storage
fonctionnant en parallèle, comme illustré sur le schéma
\ref{example-demultiplexer} p.\pageref{example-demultiplexer}.

![Exemple de répartition des requêtes \label{example-demultiplexer}](example_demultiplexer.pdf)

####

On introduit donc une nouvelle classe héritant de `ObjStorage` dont le
rôle est de dupliquer les requêtes et de les déléguer à plusieurs
object storages (voir schéma \ref{objstorage-multiplexer}
p.\pageref{objstorage-multiplexer})

![Ajout du Multiplexer dans la hiérarchie ObjStorage \label{objstorage-multiplexer}](objstorage_multiplexer.pdf)

####

En revanche, lorsqu'un contenu est ajouté et qu'il doit être placé
dans une partition qui a déjà été migrée, il ne faut l'ajouter que
dans la nouvelle version de l'object storage. Il est donc nécessaire
de pouvoir filtrer les accès aux storages. A cette fin, on ajoute un
nouvel intermédiaire entre le multiplexer et l'object storage qui est
capable de filtrer les appels de l'API et d'empêcher certaines actions
d'être effectuées sur les object storages filtrés.

####

La classe `FilterObjStorage` est donc une classe qui sert de proxy
pour un object storage, qui hérite de `ObjStorage` pour en conserver
l'API et qui autorise certaines actions en bloquant les autres. Les
méthodes d'un `FilterObjStorage` ne font aucune action lorsque celle
demandée n'est pas autorisée, ou délèguent à un champ de type
`ObjStorage` les actions à effectuer.

```python
	# This is an example that does not cover the full API
	class FilterObjStorage(ObjStorage):
		""" Base class of filter """
		def __init__(self, objstorage):
			self.delegate = objstorage

		# Functions do nothing by default
		def get(self, obj_id):
			return

		def add(self, bytes, obj_id):
			return

	class ReadObjStorage(FilterObjStorage):
		""" Filter that only allows read operations. """
		def get(self, obj_id):
			return self.storage.get(obj_id)

		# self.add is not defined so it does nothing.
```

####

Comme un filtre bloque certaines actions puis délègue à un
`ObjStorage`, il est possible de chaîner les filtres afin de créer une
chaine de délégation qui permet d'appliquer plusieurs filtres et
d'avoir un résultat complexe de manière invisible.

####

Les types de filtre crées sont les suivants (voir schéma
\ref{objstorage-filter} p.\pageref{objstorage-filter}).

* **ReadObjStorageFilter** n'autorise que les opérations de lecture,
  faisant de l'object storage un stockage en lecture seule.
* **PrefixIdObjStorageFilter** autorise les opérations sur des objets
  dont l'identifiant (le sha1) contient un préfixe donné en argument.
* **RegexIdObjStorageFilter** autorise les opérations lorsque
  l'identifiant de l'objet correspond à l'expression régulière passée
  en argument.

####

![Architecture du filtre d'object storage \label{objstorage-filter}](objstorage_filter.pdf)

####

Ces trois types de filtre permettent de faire fonctionner notre
scénario d'utilisation, comme illustré sur le schéma
\ref{example-filter} p.\pageref{example-filter}.

####

![Fonctionnement de l'object storage filter \label{example-filter}](example_filter.pdf)


### Accès Cloud

####

Le but de Software Heritage nécessite d'avoir plusieurs serveur qui
peuvent servir de sauvegarde, ou d'un autre point d'accès. Pour cette
raison, l'utilisation de clouds distants (voir
\ref{ouverture-au-cloud} p.\pageref{ouverture-au-cloud}) représente
une addition importante.

####

Afin de normaliser les accès aux object storages, il n'est pas
envisageable d'utiliser directement l'API des clouds pour y stocker
des fichiers, mais il est préférable d'utiliser celle de l'object
storage. Une nouvelle implantation de `ObjStorage` sert
d'intermédiaire pour accéder aux clouds, en utilisant la librairie
Apache Libcloud qui permet de plus de faire abstraction du cloud
utilisé en masquant les différentes API Http, comme indiqué sur le
schéma \ref{objstorage-cloud} p.\pageref{objstorage-cloud}.

####

![Ajout d'un object storage se connectant à un cloud \label{objstorage-cloud}](objstorage_cloud.pdf)


### Extraction du package

####

Avec tous ces ajouts, le module `swh.storage.objstorage` s'étoffe et
devient suffisamment important pour justifier qu'il soit contenu dans
son propre package sous `swh.objstorage`.

####

Extraire le code de l'object storage depuis `swh.storage.objstorage`
vers `swh.objstorage` se fait vers un dépôt différent
(`swh-environment/swh-objstorage`). Ce dépôt doit contenir tous les
commits relatifs à l'object storage afin d'en conserver tout
l'historique de développement.

####

* Cloner le dépôt initial
* Utiliser `git --subdirectory-filter` pour ne conserver que le contenu
  de `swh/storage/objstorage`
* Changer l'url remote du dépôt pour celle d'un nouveau dépôt
* Publier les modifications sur le nouveau dépôt qui est initialisé
  avec uniquement les fichiers souhaités.

####

```sh
  git clone https://forge.softwareheritage.org/diffusion/DOBJS/swh-objstorage.git
  cd swh-storage
  git filter-branch --prune-empty --subdirectory-filter objstorage
  git remote set-url remote https://forge.softwareheritage.org/diffusion/DOBJS/swh-objstorage.git
  # Effectuer les autres operations pour agencer le depot ici.
  git push -u origin # Publier le nouveau depot
```

####

Après ces opérations, le nouveau dépôt `swh-objstorage` est initialisé
avec le contenu requis.


### Changement de l'API

####

Au cours du développement d'autres fonctionnalités, le besoin s'est
fait sentir de récupérer des contenus par lot. Dans le cas d'un object
storage local, itérer sur les requêtes suffit. Mais pour les versions
remote de l'object storage, il s'agit d'une grande perte d'efficacité
car les requêtes Http sont multipliées.

####

Afin de permettre des requêtes par lot, l'API de `ObjStorage` est
enrichie de la méthode `list(bytes):
get_batch(list(obj_id))`. Celle-ci possède une implantation par défaut
dans `ObjStorage` (qui devient conceptuellement une classe abstraite
plutôt qu'une interface, cette nuance n'existant pas en python) qui
suffit pour la plupart des cas d'utilisation.

####

```python
	get_batch(self, obj_ids):
		for obj_id in obj_ids:
			try:
				yield self.get(obj_id)
			except ObjNotFoundError:
				yield None
```

####

Calquée sur `content_get` de la classe `Storage`, cette méthode est un
générateur qui produit les contenus des storages ou `None` si l'id
n'existe pas dans l'object storage.

####

Cette méthode est redéfinie dans `RemoteObjStorage` afin de faire
transiter la requête en une seule fois vers le serveur.


### Initialisation des object storages

####

Toute l'architecture basée sur `ObjStorage` ne contient qu'une seule
classe ayant réellement un impact sur le disque, les autres ne faisant
que déléguer ces opérations.

####

Les classes qui utilisent un object storage (`Storage`, archiver, ...)
sont toutes configurées par un fichier externe. Ce fichier doit
contenir des informations sur l'object storage utilisé. Cette
configuration est complexe et nécessite un langage de description
structuré. Le fait que les object storages délèguent à un autre object
storage les actions permet d'écrire le fichier de configuration comme
un arbre.

####

Par exemple, la configuration suivante donne le résultat du schéma
\ref{example-demultiplexer} p.\pageref{example-demultiplexer}.

```yml
	storages:
		cls: multiplexer
		args:
			storages:
				- cls: pathslicing
				  args:
					  root: /srv/swh/objects
					  slicing: 0:1/0:5
				- cls: pathslicing
				  args:
					  root: /srv/swh/objects2
					  slicing: 0:2/2:4/4:6
```

####

L'architecture issue de `ObjStorage` est conçue pour être facilement
extensible, en contenant un grand nombre de classes abstraites
intermédiaires, permettant à chaque type de storage d'être spécialisé
avec peu d'ajout de code. Le module permettant de parser ce fichier de
configuration et de créer un `ObjStorage` doit donc aussi être facile
à étendre afin qu'un nouvel `ObjStorage` nécessite peu de
modifications pour être instancié.

####

La configuration d'un object storage est de la forme :

```yaml
	cls: <class identifier>
	args:
		<class's __init__ args1 name>: <value>
		...
		<class's __init__ argsN name>: <value>
```

Ce qui permet, à l'aide d'une simple table `identifiant` -> `classe`
d'obtenir la classe python à partir de l'identifiant, et d'appeler
son constructeur avec les arguments.

```python
	_STORAGE_CLASSES = {
		'pathslicing': PathSlicingObjStorage,
		'remote': RemoteObjStorage,
	}


	def get_objstorage(cls, args):
		""" Create an ObjStorage using the given implementation class.

		Args:
			cls (str): objstorage class unique key contained in the _STORAGE_CLASSES dict.
			args (dict): arguments for the required class of objstorage
				that must match exactly the one in the `__init__` method of the class.
		Returns:
			subclass of ObjStorage that match the given `cls` argument.
		Raises:
			ValueError: if the given storage class is not a valid objstorage key.
		"""
		try:
			return _STORAGE_CLASSES[cls](**args)
		except KeyError:
			raise ValueError('Storage class %s does not exists' % cls)
```


<!-- ## Content integrity checker -->
<!-- TODO: do if enough time -->
<!-- - Implémentation de base -->
<!-- - Modification suite à l'ajout du statut corrupted + Refactor pour -->
<!--   extension facile -->
